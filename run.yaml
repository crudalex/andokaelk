---

- name: setup
  hosts: all
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
  tasks:
    - name: setup
      debug: msg="gathered info from host" 
      
- name: setup nodes
  hosts: nodes
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars 
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
  tasks:
    - name: make sure that the project staging directory exists
      file: path={{ project_stage_dir }} state=directory
    - name: send the docker-compose binary
      copy: src="docker-compose" dest={{ project_stage_dir }}/docker-compose
    - name: make docker-compose executable
      file: path={{ project_stage_dir }}/docker-compose mode=0755

- name: setup the kafka cluster on nodes
  hosts: nodes
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars 
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
    - node_id: "{% for node in groups.nodes %}{% if inventory_hostname==node %}{{ -1 + loop.index }}{% endif %}{% endfor %}"
    - compose_command: "up -d"
  roles:
    - kafka

- name: setup the elasticsearch cluster on nodes
  hosts: nodes
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars 
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
    - node_id: "{% for node in groups.nodes %}{% if inventory_hostname==node %}{{ -1 + loop.index }}{% endif %}{% endfor %}"
    - compose_command: "up -d"
  roles:
    - elasticsearch

- name: setup the logstash connectors on nodes
  hosts: nodes
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars 
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
    - node_id: "{% for node in groups.nodes %}{% if inventory_hostname==node %}{{ -1 + loop.index }}{% endif %}{% endfor %}"
    - compose_command: "up -d"
  roles:
    - { role: logstash, type: "connector", template: "logstash_connector.conf", compose: "docker-compose-connector.yaml" }

- name: setup receiver and auth proxy
  hosts: gateway
  vars_files:
    - vars/common_vars 
    - vars/common_vault
    - vars/vars 
    - vars/vault
  vars:
    - project_stage_dir: "{{ stage_dir }}/{{ project_id }}/{{ inventory_hostname }}"
    - compose_command: "up -d"
    - host_ip: "{{ hostvars[inventory_hostname]['ansible_default_ipv4']['address'] }}"
    - node_id: ""
  pre_tasks:
    - name: make sure that the staging directory exists
      file: path={{ stage_dir }} state=directory
    - name: create project folder at staging directory
      file: path={{ project_stage_dir }} state=directory
    - name: send the docker-compose binary
      copy: src="docker-compose" dest={{ project_stage_dir }}/docker-compose
    - name: make docker-compose executable
      file: path={{ project_stage_dir }}/docker-compose mode=0755
  roles:
    - kibana
    - { role: auth, role_id: kibana, server_cert: "{{ kibana_cert }}", server_key: "{{ kibana_key }}", access_host: "{{ kibana_access_host }}", access_port: "{{ kibana_access_port }}", upstream_host: "kibana", upstream_port: "{{ kibana_port }}", access_white_list: "kibana_access_white_list" }
    - { role: auth, role_id: elasticsearch, server_cert: "{{ elasticsearch_cert }}", server_key: "{{ elasticsearch_key }}", access_host: "{{ elasticsearch_access_host }}", access_port: "{{ elasticsearch_access_port }}", upstream_host: "elasticsearch0", upstream_port: "{{ elasticsearch_port_start }}", access_white_list: "elasticsearch_access_white_list" }
