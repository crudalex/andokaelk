input {
  file {
    path => "/tmp/logstash/input/*.log"
  }
}
filter {
  grok {
    match => { 
        "message" => '(?<sessionlog>%{IPORHOST:ip_address} - (?<user>([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,4})|(-)|([a-zA-Z0-9._%+-]+)) \[%{HTTPDATE:timestamp}\] %{HOSTPORT:header} %{WORD:verb} (?<upstream>(%{HOSTPORT})|(-)) "%{URIPATHPARAM:request}" HTTP/%{NUMBER:httpversion} %{QS:agent} %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{NUMBER:duration})|(?<syslog>(?<timestamp>%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME}) (?<msg>.*))' 
    }
  }
  if [sessionlog] =~ /.+/ {
    mutate {
        add_field => { 
            "type" => "sessionlog" 
        }
        remove_field => ["sessionlog"]
    }
    date {
        match => ["timestamp","dd/MMM/YYYY:HH:mm:ss Z"]
        locale => en
        remove_field => ["timestamp"]
    }
    useragent {
        source => "agent"
        target => "useragent"
    }
    geoip {
        source => "ip_address"
        target => "geoip"
        database => "/usr/share/logstash/logstash-2.2.0/GeoLiteCity.dat"
    }
  } else if [syslog] =~ /.+/ {
    mutate {
        add_field => { 
            type => "syslog" 
        }
        remove_field => ["syslog"]
    }
    date {
        match => ["timestamp","YYYY/MM/dd HH:mm:ss"]
        locale => en
        remove_field => ["timestamp"]
    }
  }
}
output {
  kafka {
    codec => "json"
    bootstrap_servers => "{% for node in groups.nodes %}kafka{{ loop.index-1 }}:{{ kafka_port_start+loop.index-1 }}{% if not loop.last %},{% endif %}{% endfor %}"
    topic_id => "{{ role_id }}-access"
  }
}